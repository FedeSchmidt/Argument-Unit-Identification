{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6211788,"sourceType":"datasetVersion","datasetId":3304856}],"dockerImageVersionId":30476,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.auto import tqdm\nimport json\nimport copy\nimport random\nimport time\nimport torch\nfrom torch import nn, cuda, optim\nfrom torch.utils.data import DataLoader\ndevice = 'cuda' if cuda.is_available() else 'cpu'\nif device == 'cuda':\n    torch.cuda.empty_cache()\nprint(device)\n\ntry:\n    from torchcrf import CRF\nexcept:\n    !pip install pytorch-crf\n    from torchcrf import CRF\n\nfrom transformers import (\n    BertModel,\n    BertForTokenClassification,\n    BertTokenizerFast,\n    AutoTokenizer,\n    AutoModelForTokenClassification,\n    get_linear_schedule_with_warmup\n)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    f1_score,\n    accuracy_score,\n    precision_score,\n    recall_score,\n    precision_recall_fscore_support,\n    classification_report\n)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef generate_random_seed():\n    return random.randint(1, 1000)\n\ndef set_random_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-04T17:45:52.201814Z","iopub.execute_input":"2024-03-04T17:45:52.202791Z","iopub.status.idle":"2024-03-04T17:46:22.578278Z","shell.execute_reply.started":"2024-03-04T17:45:52.202754Z","shell.execute_reply":"2024-03-04T17:46:22.577242Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cpu\nCollecting pytorch-crf\n  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\nInstalling collected packages: pytorch-crf\nSuccessfully installed pytorch-crf-0.7.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/unit-segmentation-lstm-transformers/we.csv\n/kaggle/input/unit-segmentation-lstm-transformers/mix1.csv\n/kaggle/input/unit-segmentation-lstm-transformers/pe.csv\n/kaggle/input/unit-segmentation-lstm-transformers/abam.csv\n/kaggle/input/unit-segmentation-lstm-transformers/mix2.csv\n/kaggle/input/unit-segmentation-lstm-transformers/ug.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"configuration = {\n    'train': 'mix1', \n    'test': ['pe', 'we', 'abam', 'ug', 'mix1'],\n    'runs': 10,\n    'epochs': 10,\n    'train_batch_size': 32,\n    'dev_batch_size': 32,\n    'test_batch_size': 32,\n    'label_list': ['O', 'B', 'I'],\n    'model_checkpoint': 'bert-base-uncased',\n    'crf': False,\n    'lr': 1e-4\n}","metadata":{"execution":{"iopub.status.busy":"2023-08-01T22:48:54.778868Z","iopub.execute_input":"2023-08-01T22:48:54.779262Z","iopub.status.idle":"2023-08-01T22:48:54.786249Z","shell.execute_reply.started":"2023-08-01T22:48:54.779231Z","shell.execute_reply":"2023-08-01T22:48:54.785178Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\"\"\" Tokenize examples in batch\nSince the tokenizer may divide each token into two or more subtokens, we must align the new tokens with the original labels.\nNew subtokens must have the same label than their parent token\nLabels may be 0, 1 or 2 for O, B and I labels, respectively, and -100 for complementary tokens, such PAD, SEP, CLS tokens.\nLoss functions will ignore labels with value -100, so the loss only considers mistakes at the positions of real input (sub)tokens.\n\"\"\"\ndef tokenize_and_align_labels(txts, lbls, tokenizer, max_len = 128, mapping = None):\n\n    tokenized_inputs = tokenizer(txts, is_split_into_words=True,\n                                 max_length = max_len, padding = 'max_length', truncation=True,\n                                 return_tensors = 'pt')\n\n    labels = []\n    for i, label in enumerate(lbls):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        previous_label = None\n        label_ids = []\n        for word_idx in word_ids:\n            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n            # ignored in the loss function.\n            if word_idx is None:\n                label_ids.append('O')\n            # We set the label for the first token of each word.\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n                previous_label = label[word_idx]\n            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n            # the label_all_tokens flag.\n            else:\n                new_label = 'O'\n                if previous_label == 'O':\n                    new_label = 'O'\n                    # label_ids.append('O')\n                else:\n                    suffix_label = label[word_idx][1:]\n                    new_label = 'I'+suffix_label\n                label_ids.append(new_label)\n                previous_label = new_label\n\n            previous_word_idx = word_idx\n\n        labels.append(label_ids)\n\n    if mapping is not None:\n        labels = [list(map(lambda x : mapping.index(x), x)) for x in labels]\n\n    return tokenized_inputs, labels\n\n\"\"\"\nReturn text tokens from the tokenizer given the numeric input ids\n\"\"\"\ndef get_tokens_from_ids(input_ids):\n\n    return [tokenizer.convert_ids_to_tokens(tl) for tl in input_ids]\n\n\"\"\"\nRemove part of predicted sequences corresponding to padding tokens.\n\"\"\"\ndef remove_padding_from_predictions(predictions, batch_attention_mask):\n    valid_predictions_list = []\n    for instance_preds, att_mask in zip(predictions, batch_attention_mask):\n        valid = [pred for pred, mask in zip(instance_preds, att_mask) if mask == 1]\n        valid_predictions_list.append(valid[1:-1])\n        \n    return valid_predictions_list\n\ndef remove_padding_and_get_tokens(batch_ids, batch_attention_mask):\n    valid_ids_list = []\n    for instances_ids, att_mask in zip(batch_ids, batch_attention_mask):\n        valid = [ids for ids, mask in zip(instances_ids, att_mask) if mask == 1]\n        valid_ids_list.append(valid[1:-1])\n    \n    valid_tokens = get_tokens_from_ids(valid_ids_list)\n    return valid_tokens\n\n\"\"\"\nMaps sequences of integer to sequences of BIO tags\n\"\"\"\ndef integer_to_bio(labels, mapping):\n    return [[mapping[int(x)] for x in l] for l in labels]\n\n\"\"\"\nTransforms list of predicted sequences to a flat list of labels.\n\"\"\"\ndef flatten_predictions(labels):\n    return [j for sub in labels for j in sub]\n\n\"\"\"\nGenerates txt file with tokens, labels and predictions. Estilo FLAiR NLP.\n\"\"\"\ndef generate_results_txt(tokens, labels, predictions, output_file_name):\n    \n    with open(output_file_name, 'w', encoding = 'utf-8') as nf:\n\n        for tks, lbs, prds in zip(tokens, labels, predictions):\n            for tk, lb, pr in zip(tks, lbs, prds):\n                nf.write(f\"{tk} {lb} {pr}\\n\")\n\n            nf.write(f\"\\n\")\n\n\"\"\"\nDataset class for sequence labeling\n\"\"\"\nclass SequenceLabelingDataset(torch.utils.data.Dataset):\n    def __init__(self, df, tokenizer, label_list):\n        MAX_LEN = 128\n        lb = [x.split() for x in df.labels.values.tolist()]\n        txt = [i.split() for i in df.tokens.values.tolist()]\n        self.encodings, self.labels = tokenize_and_align_labels(txt, \n                                                                lb, \n                                                                tokenizer, \n                                                                max_len = MAX_LEN, \n                                                                mapping = label_list)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n    \n    \n\"\"\"\nModel for sequence labeling\n\"\"\"\nclass SimpleTagger(nn.Module):\n    def __init__(self, model_checkpoint, num_labels = 3):\n        super(SimpleTagger, self).__init__()\n        self.model_checkpoint = model_checkpoint\n        self.num_labels = num_labels\n        self.transf = AutoModelForTokenClassification.from_pretrained(self.model_checkpoint, num_labels = self.num_labels)\n    \n    def forward(self, input_ids, attention_mask, token_type_ids = None, labels = None):\n        \n        if labels is not None: # training\n            outputs = None\n            if token_type_ids is not None:\n                outputs = self.transf(input_ids = input_ids, \n                                    token_type_ids = token_type_ids, \n                                    attention_mask = attention_mask, \n                                    labels = labels)\n            else:\n                outputs = self.transf(input_ids = input_ids, \n                                    attention_mask = attention_mask, \n                                    labels = labels)\n            loss = outputs.loss\n            logits = np.argmax(outputs.logits.detach().cpu().numpy(), axis = 2).tolist()\n            return loss, logits\n        else: # inference\n            if token_type_ids is not None:\n                outputs = self.transf(input_ids = input_ids, \n                                    token_type_ids = token_type_ids, \n                                    attention_mask = attention_mask)\n            else:\n                outputs = self.transf(input_ids = input_ids, \n                                    attention_mask = attention_mask)\n#             outputs = self.bert(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n            return np.argmax(outputs.logits.detach().cpu().numpy(), axis = 2).tolist()\n\n# \"\"\"\n# Model for sequence labeling - Longformer + CRF\n# \"\"\"\nclass TaggerWithCRF(nn.Module):\n    def __init__(self, model_checkpoint, num_labels = 3):\n        super(TaggerWithCRF, self).__init__()\n        self.model_checkpoint = model_checkpoint\n        self.num_labels = num_labels\n        self.transf = AutoModelForTokenClassification.from_pretrained(self.model_checkpoint, num_labels = self.num_labels)\n        self.crf = CRF(self.num_labels, batch_first = True)\n        \n    def forward(self, input_ids, attention_mask, token_type_ids = None, labels = None):\n        outputs = None\n        if token_type_ids is not None:\n            outputs = self.transf(input_ids = input_ids, \n                                  token_type_ids = token_type_ids, \n                                  attention_mask = attention_mask)\n        else:\n            outputs = self.transf(input_ids = input_ids, \n                                  attention_mask = attention_mask)\n        \n        logits = outputs.logits\n        \n#         print(logits.shape)\n\n        if labels is not None: # training\n            loss = -self.crf(logits, labels, mask = attention_mask.byte(), reduction = 'token_mean')\n            return loss, self.crf.decode(logits)\n        else: # inference\n            return self.crf.decode(logits)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T22:49:01.641918Z","iopub.execute_input":"2023-08-01T22:49:01.642282Z","iopub.status.idle":"2023-08-01T22:49:01.677152Z","shell.execute_reply.started":"2023-08-01T22:49:01.642252Z","shell.execute_reply":"2023-08-01T22:49:01.676199Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def load_training_data(df_name, TRAIN_BATCH_SIZE = 32, DEV_BATCH_SIZE = 32):\n    \n    # TOKENIZER\n    tokenizer_seq = AutoTokenizer.from_pretrained(model_checkpoint)\n    \n    # SEQUENCE LABELING DATASET\n    df = pd.read_csv(f'/kaggle/input/unit-segmentation-lstm-transformers/{df_name}.csv')\n    \n    train_seq_df, dev_seq_df = None, None\n    \n    if 'dev' in df.set.unique():\n        train_seq_df = df.loc[df['set'] == 'train']\n        dev_seq_df = df.loc[df['set'] == 'dev']\n    else:\n        train_seq_df = df.loc[df['set'] == 'train']\n        train_seq_df, dev_seq_df = train_test_split(train_seq_df, test_size = 0.1, random_state = 2023)\n        \n    train_seq_df = train_seq_df.sample(frac = 1)\n    dev_seq_df = dev_seq_df.sample(frac = 1)\n    \n    print(train_seq_df.shape, dev_seq_df.shape)\n    \n    # PYTORCH DATASETS\n    train_dataset = SequenceLabelingDataset(train_seq_df, tokenizer_seq, label_list)\n    val_dataset = SequenceLabelingDataset(dev_seq_df, tokenizer_seq, label_list)\n    \n    # DATALOADERS\n    train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=DEV_BATCH_SIZE, shuffle=True)\n    \n    return train_loader, val_loader, tokenizer_seq\n    \ndef load_testing_data(df_name, tokenizer, TEST_BATCH_SIZE = 32):\n\n    # SEQUENCE LABELING DATASET\n    df = pd.read_csv(f'/kaggle/input/unit-segmentation-lstm-transformers/{df_name}.csv')\n    \n    test_seq_df = df.loc[df['set'] == 'test']\n    \n    # PYTORCH DATASETS\n    test_dataset = SequenceLabelingDataset(test_seq_df, tokenizer, label_list)\n    \n    # DATALOADERS\n    test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)\n    \n    return test_loader","metadata":{"execution":{"iopub.status.busy":"2023-08-01T22:49:03.620695Z","iopub.execute_input":"2023-08-01T22:49:03.621516Z","iopub.status.idle":"2023-08-01T22:49:03.631271Z","shell.execute_reply.started":"2023-08-01T22:49:03.621480Z","shell.execute_reply":"2023-08-01T22:49:03.630307Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, optimizer):\n\n    # progress_bar\n    # num_train_optimization_steps = len(train_loader)\n#     progress_bar = tqdm(range(len(train_loader)))\n\n    model.train()\n\n    train_loss = 0\n    for batch in train_loader:\n        batch = tuple(v.to(device) for t, v in batch.items())\n        loss, outputs = None, None\n        \n        if model_checkpoint.startswith('bert'):\n            batch_input_ids, batch_token_type_ids, batch_attention_mask, batch_labels = batch\n            loss, outputs = model(batch_input_ids, \n                                  token_type_ids = batch_token_type_ids,\n                                  attention_mask = batch_attention_mask, \n                                  labels = batch_labels)\n        else:\n            batch_input_ids, batch_attention_mask, batch_labels = batch\n            loss, outputs = model(batch_input_ids, \n                                  attention_mask = batch_attention_mask, \n                                  labels = batch_labels)\n\n        \n\n        train_loss += loss.item()\n\n        # backprop\n        optimizer.zero_grad()\n        \n        loss.backward()\n        \n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n\n        optimizer.step()\n\n#         progress_bar.update(1)\n\n    avg_train_loss = train_loss / len(train_loader)\n    return avg_train_loss\n\ndef evaluate_model(model, dataloader):\n\n    model.eval()\n\n    eval_loss = 0\n    eval_labels, eval_predictions = [], []\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            batch = tuple(v.to(device) for t, v in batch.items())\n            loss, outputs = None, None\n            \n            if model_checkpoint.startswith('bert'):\n                batch_input_ids, batch_token_type_ids, batch_attention_mask, batch_labels = batch\n                loss, outputs = model(batch_input_ids, \n                                      token_type_ids = batch_token_type_ids,\n                                      attention_mask = batch_attention_mask, \n                                      labels = batch_labels)\n            else:\n                batch_input_ids, batch_attention_mask, batch_labels = batch\n                loss, outputs = model(batch_input_ids, \n                                      attention_mask = batch_attention_mask, \n                                      labels = batch_labels)\n\n            eval_loss += loss.item()\n            \n            valid_labels = remove_padding_from_predictions(batch_labels.detach().cpu().numpy(), batch_attention_mask.detach().cpu().numpy())\n            eval_labels += valid_labels\n            \n            valid_predictions = remove_padding_from_predictions(outputs, batch_attention_mask.detach().cpu().numpy())\n            eval_predictions += valid_predictions\n    \n    flattened_labels = flatten_predictions(eval_labels)\n    flattened_predictions = flatten_predictions(eval_predictions)\n    \n    eval_f1 = f1_score(flattened_labels, flattened_predictions, average = 'macro')\n    return eval_loss / len(dataloader), eval_f1\n\n\ndef test_model(model, dataloader, write_file = False, path_file = None):\n\n    model.eval()\n\n    eval_tokens, eval_labels, eval_predictions = [], [], []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            batch = tuple(v.to(device) for t, v in batch.items())\n            loss, outputs = None, None\n            \n            if model_checkpoint.startswith('bert'):\n                batch_input_ids, batch_token_type_ids, batch_attention_mask, batch_labels = batch\n                _, outputs = model(batch_input_ids, \n                                      token_type_ids = batch_token_type_ids,\n                                      attention_mask = batch_attention_mask, \n                                      labels = batch_labels)\n            else:\n                batch_input_ids, batch_attention_mask, batch_labels = batch\n                _, outputs = model(batch_input_ids, \n                                      attention_mask = batch_attention_mask, \n                                      labels = batch_labels)\n\n            valid_labels = remove_padding_from_predictions(batch_labels.detach().cpu().numpy(), batch_attention_mask.detach().cpu().numpy())\n            eval_labels += valid_labels\n            \n            valid_predictions = remove_padding_from_predictions(outputs, batch_attention_mask.detach().cpu().numpy())\n            eval_predictions += valid_predictions\n            \n            valid_tokens = remove_padding_and_get_tokens(batch_input_ids.detach().cpu().numpy(), \n                                                         batch_attention_mask.detach().cpu().numpy())\n            eval_tokens += valid_tokens\n            \n    if write_file:\n        generate_results_txt(eval_tokens, eval_labels, eval_predictions, path_file)\n    \n    return eval_labels, eval_predictions","metadata":{"execution":{"iopub.status.busy":"2023-08-01T22:49:05.484008Z","iopub.execute_input":"2023-08-01T22:49:05.484378Z","iopub.status.idle":"2023-08-01T22:49:05.504939Z","shell.execute_reply.started":"2023-08-01T22:49:05.484346Z","shell.execute_reply":"2023-08-01T22:49:05.504002Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# MODEL CONFIGURATION\nTAGGER_USING_CRF = configuration['crf']\nmodel_checkpoint = configuration['model_checkpoint']\nmodel_name = model_checkpoint.split('-')[0]\nif TAGGER_USING_CRF:\n    model_name += '-crf'\nlabel_list = configuration['label_list']\nnum_labels = len(label_list)\n\n# TRAINING CONFIGURATION\nRUNS = configuration['runs']\nEPOCHS = configuration['epochs']\nTRAIN_BATCH_SIZE = configuration['train_batch_size']\nTEST_BATCH_SIZE = configuration['test_batch_size']\nDEV_BATCH_SIZE = configuration['dev_batch_size']\ntrain_df = configuration['train']\ntest_dfs = configuration['test']\n\n# MISCELLANEOUS\nSAVE_INFORMATION = True\nSAVE_BEST_MODEL = True\n\n# ======================================== #\ntraining_info, testing_info, models_info = [], [], []\nstart_time = time.time()\nfor nrun in range(RUNS):\n    # Initialize\n    rs = generate_random_seed()\n    set_random_seed(rs)\n    \n    best_eval_loss = float('inf')\n    best_epoch = 0\n    best_model_state = None\n    \n    # Dataloaders\n    train_loader, val_loader, tokenizer = load_training_data(train_df, TRAIN_BATCH_SIZE=TRAIN_BATCH_SIZE, DEV_BATCH_SIZE=DEV_BATCH_SIZE)\n    \n    # Create model\n    tagger = None\n    if TAGGER_USING_CRF:\n        tagger = TaggerWithCRF(model_checkpoint, num_labels = num_labels)\n    else:\n        tagger = SimpleTagger(model_checkpoint, num_labels = num_labels)\n\n    tagger.to(device)\n    \n    # OPTIMIZER\n    optimizer = torch.optim.AdamW(tagger.parameters(), lr = configuration['lr'], eps = 1e-8)\n    \n    # Training loop\n    for epoch in range(EPOCHS):\n        print(f\"{epoch+1}/{EPOCHS}\")\n        # train one epoch\n        train_loss = train_model(tagger, train_loader, optimizer)\n        \n        # evaluate model\n        eval_loss, eval_f1 = evaluate_model(tagger, val_loader)\n        \n        training_info.append((nrun, rs, epoch, train_loss, eval_loss, eval_f1)) # nrun, epoch, train_loss, eval_loss, eval_f1\n        \n        # save best model based on validation loss\n        if eval_loss < best_eval_loss:\n            best_eval_loss = eval_loss\n            best_epoch = epoch\n            best_model_state = copy.deepcopy(tagger.state_dict())\n            \n    print(f\"Best epoch: {best_epoch} - Validation loss: {best_eval_loss} [Run: {nrun}]\")\n    \n    # Testing\n    # Loading best model\n    best_tagger = None\n    if TAGGER_USING_CRF: \n        best_tagger = TaggerWithCRF(model_checkpoint, num_labels = num_labels)\n    else:\n        best_tagger = SimpleTagger(model_checkpoint, num_labels = num_labels)\n    \n    best_tagger.load_state_dict(best_model_state)\n    best_tagger.to(device)\n    eval_results = evaluate_model(best_tagger, val_loader)\n    print(eval_results) # check model\n    \n    macros = []\n    for test_df in test_dfs:\n        test_loader = load_testing_data(test_df, tokenizer, TEST_BATCH_SIZE = TEST_BATCH_SIZE)\n        path_test_results_file = f'results-{train_df}-{test_df}-{model_name}-{nrun}.txt'\n        tlabels, tpredictions = test_model(best_tagger, test_loader, write_file = True, path_file = path_test_results_file)\n        \n        flattened_labels = flatten_predictions(tlabels)\n        flattened_predictions = flatten_predictions(tpredictions)\n        report_info = classification_report(flattened_labels, flattened_predictions, target_names = label_list, output_dict = True)\n        accuracy, macro_f1 = report_info['accuracy'], report_info['macro avg']['f1-score']\n        o_f1, b_f1, i_f1 =  report_info['O']['f1-score'], report_info['B']['f1-score'], report_info['I']['f1-score']\n        macros.append(macro_f1)\n    \n        testing_info.append((nrun, train_df, test_df, len(tpredictions), accuracy, macro_f1, o_f1, b_f1, i_f1)) # nrun, train, test, sequences, acc, macrof1, Of1, Bf1, If1\n    \n    print(f\"Test Macros F1: {test_dfs}: {macros} [Run: {nrun}]\")\n    \n    if SAVE_BEST_MODEL:\n        model_path = f\"model-{train_df}-{model_name}-{nrun}.pt\"\n        models_info.append((nrun, model_path))\n        if best_model_state is not None:\n            torch.save(best_model_state, model_path)\n        else:\n            torch.save(tagger.state_dict(), model_path)\n    \n# Save data    \nif SAVE_INFORMATION:\n    models_file_name = f\"models-{train_df}-{model_name}.csv\"\n    pd.DataFrame(models_info, columns = ['run', 'model_file']).to_csv(models_file_name, index = False)\n    \n    train_file_name = f'train-info-{train_df}-{model_name}.csv'\n    pd.DataFrame(training_info, columns = ['run', 'seed', 'epoch', 'train_loss', 'eval_loss', 'eval_f1']).to_csv(train_file_name, index = False)\n    \n    test_file_name = f'test-info-{train_df}-{model_name}.csv'\n    pd.DataFrame(testing_info, columns = ['run', 'train', 'test', 'sequences', 'accuracy', 'macro-f1', 'O-f1', 'B-f1', 'I-f1']).to_csv(test_file_name, index = False)\n\nprint(f\"Total time: {((time.time() - start_time)//60)+1} minutes.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T22:49:08.307048Z","iopub.execute_input":"2023-08-01T22:49:08.307409Z","iopub.status.idle":"2023-08-02T02:06:23.947956Z","shell.execute_reply.started":"2023-08-01T22:49:08.307380Z","shell.execute_reply":"2023-08-02T02:06:23.945472Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f5d1d05c2184a2d91467c9e181efe66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c54bfec6f52411abef4d80e11c89ce3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e34ee3e49b40412ca950857abf2950f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c052b0605714f44adc8bd948e8d4522"}},"metadata":{}},{"name":"stdout","text":"(9512, 5) (1057, 5)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83cfee9c7e1048a58437456358dca3ba"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 0 - Validation loss: 0.06624407608829 [Run: 0]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.06667538617244538, 0.791605593443887)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.8179544440324714, 0.7955431848724809, 0.7506768717946691, 0.34389489363066567, 0.7876492790919171] [Run: 0]\n(9512, 5) (1057, 5)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 1 - Validation loss: 0.0671441684518119 [Run: 1]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.06743207157534711, 0.8043540086471728)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.8357913948516447, 0.8004074768218441, 0.7686506430233013, 0.37216013151465904, 0.8124080967390258] [Run: 1]\n(9512, 5) (1057, 5)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 0 - Validation loss: 0.07001978279474903 [Run: 2]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.065122339874506, 0.7947726847853165)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.8355752274687965, 0.8153447154136938, 0.7534128344993952, 0.33830641202637196, 0.803676401016991] [Run: 2]\n(9512, 5) (1057, 5)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 0 - Validation loss: 0.06663684667471577 [Run: 3]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.07034964026773677, 0.7850084825608432)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.8330925798398096, 0.7608256884194621, 0.761029830542741, 0.37105860686517156, 0.7936323186651065] [Run: 3]\n(9512, 5) (1057, 5)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 0 - Validation loss: 0.0648506529190961 [Run: 4]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.06423328652539674, 0.7851011516323486)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.8188088512650502, 0.8230614326334083, 0.7529412843277393, 0.3206436354020677, 0.7984110237927325] [Run: 4]\n(9512, 5) (1057, 5)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 1 - Validation loss: 0.067900034112801 [Run: 5]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.06842481821556301, 0.8034078391103395)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.8285143673724806, 0.8446692433119529, 0.7515518579606085, 0.34836321517216357, 0.8097579002964747] [Run: 5]\n(9512, 5) (1057, 5)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 0 - Validation loss: 0.07142499658991308 [Run: 6]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.06869065016508102, 0.772843745856278)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.808666020281927, 0.8392581593855785, 0.7277282250001882, 0.35926670097949387, 0.7875332760319315] [Run: 6]\n(9512, 5) (1057, 5)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 0 - Validation loss: 0.06650329151136034 [Run: 7]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.0660928628195132, 0.7918143867658599)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.8458001827358, 0.7705357760879418, 0.7662125023014617, 0.3690619158147617, 0.804535010467656] [Run: 7]\n(9512, 5) (1057, 5)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 0 - Validation loss: 0.07464511550086386 [Run: 8]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.06665432212107322, 0.7834977438737813)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.8264350889591148, 0.7653256641748918, 0.7446498261402393, 0.3752323415483974, 0.7888035214366732] [Run: 8]\n(9512, 5) (1057, 5)\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1/10\n2/10\n3/10\n4/10\n5/10\n6/10\n7/10\n8/10\n9/10\n10/10\nBest epoch: 1 - Validation loss: 0.06907985107082983 [Run: 9]\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"(0.06910185283049941, 0.7956322222417445)\nTest Macros F1: ['pe', 'we', 'abam', 'ug', 'mix1']: [0.8378480651606516, 0.8544485903899175, 0.7359409612234321, 0.3464948903620755, 0.8100520780848605] [Run: 9]\nTotal time: 198.0 minutes.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport zipfile\n\ndef zip_files(folder_path, zip_name):\n    # Crear un archivo ZIP\n    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        # Recorrer todos los archivos en la carpeta\n        for foldername, subfolders, filenames in os.walk(folder_path):\n            for filename in filenames:\n                # Comprobar si el archivo es un archivo TXT o CSV\n                if filename.endswith('.txt') or filename.endswith('.csv') or filename.endswith('.pt'):\n                    # Ruta completa del archivo\n                    file_path = os.path.join(foldername, filename)\n                    # Agregar el archivo al archivo ZIP\n                    zipf.write(file_path, os.path.relpath(file_path, folder_path))\n\n# Llamar a la función para comprimir los archivos\nfolder_path = '/kaggle/working/'\nzip_name = 'archivos2.zip'\nzip_files(folder_path, zip_name)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T02:06:23.950217Z","iopub.execute_input":"2023-08-02T02:06:23.950673Z","iopub.status.idle":"2023-08-02T02:10:48.633313Z","shell.execute_reply.started":"2023-08-02T02:06:23.950635Z","shell.execute_reply":"2023-08-02T02:10:48.632211Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# best_eval_loss = float('inf')\n# best_epoch = 0\n# best_model_state = None\n\n# PATH = None\n\n# training_info = []\n\n# # DATALOADERS\n# train_loader, val_loader, tokenizer = load_training_data(train_df, TRAIN_BATCH_SIZE=TRAIN_BATCH_SIZE, DEV_BATCH_SIZE=DEV_BATCH_SIZE)\n\n# # TAGGER\n# tagger = None\n# if TAGGER_USING_CRF:\n#     tagger = TaggerWithCRF(model_checkpoint, num_labels = num_labels)\n# else:\n#     tagger = SimpleTagger(model_checkpoint, num_labels = num_labels)\n    \n# tagger.to(device)\n\n# # OPTIMIZER\n# optimizer = torch.optim.AdamW(tagger.parameters(), lr = 1e-4, eps = 1e-8)\n\n# # TRAINING LOOP\n# for epoch in range(EPOCHS):\n    \n#     # train one epoch\n#     train_loss = train_model(tagger, train_loader, optimizer)\n\n#     # evaluate model\n#     eval_results = evaluate_model(tagger, val_loader)\n\n#     info_dict = {'epoch': epoch, 'train_loss': train_loss, 'eval_loss': eval_results[0], 'eval_f1': eval_results[1]}\n    \n#     training_info.append(tuple(info_dict.values()))\n\n#     # save best model based on validation loss\n#     eval_loss = eval_results[0]\n#     if eval_loss < best_eval_loss:\n#         best_eval_loss = eval_loss\n#         best_epoch = epoch\n#         best_model_state = copy.deepcopy(tagger.state_dict())\n            \n#     print(info_dict)\n\n# print(best_eval_loss, \"in epoch\", best_epoch)\n\n# df_cols = ['epoch', 'train_loss', 'eval_loss', 'eval_f1']\n# info_df = pd.DataFrame(training_info, columns = df_cols)\n# if SAVE_INFORMATION:\n#     file_name = f'train-info-{train_df}-{model_name}-crf.csv' if TAGGER_USING_CRF else f'train-info-{train_df}-{model_name}-nocrf.csv'\n#     info_df.to_csv(file_name, index = False)\n\n# if SAVE_BEST_MODEL:\n#     PATH = f\"model-{train_df}-{model_name}-crf.pt\" if TAGGER_USING_CRF else f\"model-{train_df}-{model_name}-nocrf.pt\"\n    \n#     if best_model_state is not None:\n#         torch.save(best_model_state, PATH)\n#     else:\n#         torch.save(tagger.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T19:11:33.906774Z","iopub.execute_input":"2023-07-31T19:11:33.907210Z","iopub.status.idle":"2023-07-31T19:11:33.915670Z","shell.execute_reply.started":"2023-07-31T19:11:33.907166Z","shell.execute_reply":"2023-07-31T19:11:33.912953Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# # Loading best model\n# if TAGGER_USING_CRF:\n#     best_tagger = TaggerWithCRF(model_checkpoint, num_labels = num_labels)\n# else:\n#     best_tagger = SimpleTagger(model_checkpoint, num_labels = num_labels)\n\n# # best_tagger.load_state_dict(best_model_state)\n# # if PATH is not None:\n# best_tagger.load_state_dict(torch.load(PATH))\n# best_tagger.to(device)\n\n# eval_results = evaluate_model(best_tagger, val_loader)\n\n# print(eval_results)\n# print(\"-\"*30)\n# print()\n\n# # Evaluation on testing sets.\n# testing_info = []\n\n# for test_df in test_dfs:\n    \n#     run_info = [train_df, test_df]\n    \n#     print(f\"MODEL TRAINED USING {train_df}\\nEVALUATED IN {test_df}\")\n    \n#     test_loader = load_testing_data(test_df, tokenizer, TEST_BATCH_SIZE = 32)\n    \n#     path_results_file = f'results-{train_df}-{test_df}-{model_name}-crf.txt' if TAGGER_USING_CRF else f'results-{train_df}-{test_df}-{model_name}-nocrf.txt'\n#     tlabels, tpredictions = test_model(best_tagger, test_loader, write_file = True, path_file = path_results_file)\n    \n#     print(f\"Total sequences in predictions: {len(tpredictions)}\")\n\n#     flattened_labels = flatten_predictions(tlabels)\n#     flattened_predictions = flatten_predictions(tpredictions)\n    \n#     report_info = classification_report(flattened_labels, flattened_predictions, target_names = label_list, output_dict = True)\n    \n#     run_info += [len(tpredictions), report_info['accuracy'], report_info['macro avg']['f1-score']]\n    \n#     for lb in label_list:\n#         run_info.append(report_info[lb]['f1-score'])\n    \n#     print(classification_report(flattened_labels, flattened_predictions, target_names = label_list))\n#     print()\n    \n#     testing_info.append(run_info)\n    \n# #     break\n\n# info_df = pd.DataFrame(testing_info, \n#                        columns = ['training', 'testing', 'sequences', 'accuracy', 'macro-f1', 'O-f1', 'b-f1', 'I-f1'])\n# if SAVE_INFORMATION:\n#     test_file_name = f'test-info-{train_df}-{model_name}-crf.csv' if TAGGER_USING_CRF else f'test-info-{train_df}-{model_name}-nocrf.csv'\n#     info_df.to_csv(test_file_name, index = False)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T19:11:33.919437Z","iopub.execute_input":"2023-07-31T19:11:33.919700Z","iopub.status.idle":"2023-07-31T19:11:33.935539Z","shell.execute_reply.started":"2023-07-31T19:11:33.919676Z","shell.execute_reply":"2023-07-31T19:11:33.934505Z"},"trusted":true},"execution_count":9,"outputs":[]}]}